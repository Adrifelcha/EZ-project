---
title: "Shape perception: <br>Hypothesis testing example"
author: "Adriana F. Chávez De la Peña and Joachim Vandekerckhove"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: true
    cards: false
    highlight: tango
    fig_width: 12 
    fig_height: 8 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmdformats)
```
# Introduction

Data from nine participants in a shape perception study conducted by [Vandekerckhove, Panis and Wagemans (2007; see experiment 3)](https://link.springer.com/article/10.3758/BF03193960). In this task, participants were **instructed to compare pairs of irregular shapes shown sequentially to indicate whether they were "Same" or "Different".** 

The experimental design included **three dichotomous factors**:

1. **Change presence**: Was there a change between the shapes?
2. **Change type**: If there was a change, was it a change in *convexity* or *concavity*?
3. **Change quality**: If there was a change, was it a *qualitative* or *quantitative* change?

The incompletely crossed design leads to five experimental conditions, distinguished by the configuration of three dummy variables $A$, $B$, and $C$:

| Condition | Change (A) | Change quality (B) | Change type (C) |
|-----------|------------|-------------------|----------------|
| k = 1     | Yes (A = 1) | Qualitative (B = 0) | Convexity (C = 0) |
| k = 2     | Yes (A = 1) | Quantitative (B = 1) | Convexity (C = 0) |
| k = 3     | Yes (A = 1) | Qualitative (B = 0) | Concavity (C = 1) |
| k = 4     | Yes (A = 1) | Quantitative (B = 1) | Concavity (C = 1) |
| k = 5     | No (A = 0)  | n/a | n/a |


```{r, message=FALSE}
# Load necessary libraries/packages
library(R2jags)
library(here)
seed <- 15
```

# Loading and cleaning the data

### Load the data

```{r}
# Load the data from nine participants
data_raw <- read.csv(here("demos", "applications", "shape_perception", "data", "vpw08.csv"))
colnames(data_raw) <- c("sub", "change_quality", "change_type", "noChange", "response", "rt")
head(data_raw)
```

```{r}
# No. of observations
nrow(data_raw)
```

### Clean the data

```{r}
# Create a copy of the data preserving only RTs <= 3 seconds
tmp <- data_raw[which(data_raw$rt<=3),]

# Add a column with the condition index
change <- 1-tmp$noChange
cond <- rep(0,nrow(tmp))
cond[which(tmp$change_quality==0&tmp$change_type==0)] <- 1
cond[which(tmp$change_quality==1&tmp$change_type==0)] <- 2
cond[which(tmp$change_quality==0&tmp$change_type==1)] <- 3
cond[which(tmp$change_quality==1&tmp$change_type==1)] <- 4
cond[which(change==0)] <- 5

# Prepare final data set to use for our analysis
data <- data.frame("sub" = tmp$sub, "cond" = cond, "change" = change, 
                   "change_quality" = tmp$change_quality, "change_type" = tmp$change_type,
                   "response" = tmp$response, "rt" = tmp$rt)
```

```{r}
# No. of observations
nrow(data)
```

# Get summary statistics

**Note:** Since the three-parameters considered by the EZDDM formulation don't predict any difference in shape between the correct and incorrect RT distributions, we use all trials to compute the mean and variance of the RT.

### Write custom function `ez_summaries`

```{r}
# Define a function to compute the summary statistics used by EZ-DDM
ez_summaries <- function(data){
  # Identify condition and subject ID
  cond <- unique(data$cond)
  sub <- unique(data$sub)
  # Prepare EZ statistics
  output<- c()
  for(i in sort(sub)){
    # For each subject...
    for(k in sort(cond)){
      # On each condition...
      # Isolate the data
      subset <- data[which(data$sub==i&data$cond==k),]
      # And prepare summary statistics
      output <- rbind(output, c("sub" = unique(subset$sub), "cond" = unique(subset$cond),
                                "change" = unique(subset$change), 
                                "change_quality" = unique(subset$change_quality),
                                "change_type" = unique(subset$change_type),
                                "nTrials" = nrow(subset), "score" = sum(subset$response),
                                "meanRT"  = mean(subset$rt), "varRT"= var(subset$rt)))
    }
  }
  # Return data frame with summary statistics per condition and subject
  return(as.data.frame(output))
}
```

### Compute summary statistics from data

```{r}
ezdata <- ez_summaries(data)
ezdata$acc_rate <- ezdata$score/ezdata$nTrials
```

# The model 

### EZHBDM

The first component of the model is what we called 'the proxy' model: We use the sampling distributions for the three summary statistics computed from the data, (i.e., the number of correct responses $\dot{T}$ and the mean $\dot{M}$ and variance $\dot{V}$ of the response times), which are built from the forward-system of equations in the EZDDM that characterize the proportion of correct responses `PC`, and the mean and precision of the RTs `MRT`, `PRT`.

\begin{align*}
\dot{T} &\sim \mbox{Binomial}(PC,N)\\
\dot{V} &\sim \mbox{Normal}(\frac{1}{PRT},\frac{N-1}{2(PRT)^2})\\
\dot{M} &\sim \mbox{Normal}(MRT, PRT \times N)\\
PC &= \frac{1}{\exp(-\alpha\nu)+1}\\
MRT &= \tau + \frac{\alpha}{2\nu}\frac{\exp(-\alpha\nu)-1}{\exp(-\alpha\nu)+1}\\
PRT &= \frac{\alpha}{2\nu^3}\{\frac{1-2\alpha\nu\exp(-\alpha\nu)-\exp(-\alpha\nu)^2}{(\exp(-\alpha\nu)+1)^2}\}
\end{align*}

### Metaregression structure with dummy variables

We model the variability in the drift rate $\nu$ parameter across conditions $k$ by fitting a multiple linear regression

\vspace{-0.2in}

\begin{align*}
\nu^{pred}_k &= \mu_\nu+X_k(\gamma_1Z_k+\gamma_2Y_k+\gamma_3Y_kZ_k)+\gamma_4(1-X_k)\\
\nu_k &\sim \mbox{Normal}(\nu^{pred}_k,\sigma_\nu)
\end{align*}

so that the drift rate predicted for every condition $\nu^{pred}_k$ depends on the configuration of the three dummy variables and their interaction with five different regression coefficients.

```{r}
# Is there a change?
# Yes (1) / No (0)
A <- ezdata$change

# Change quality
# Quantitative (1) / Qualitative (0)
B <- ezdata$change_quality

# Change type
# Concavity (1) / Convexity (0)
C <- ezdata$change_type
```


### Write the model in JAGS

```{r}
modelFile <- here("output", "BUGS-models", "demo_shape_model.bug")
model <- write("
    model {
              ####### Priors
              drift_mu ~ dnorm(0,1)   # Baseline
              drift_lambda ~ dgamma(2,1)
              drift_sigma = pow(drift_lambda, -0.5)
              nondt ~ dexp(1)
              for(i in 1:4){
                  gamma[i] ~ dnorm(0,1)   
              }      
              
              for(j in 1:5){
                  drift_pred[j] = drift_mu + A[j]*(gamma[1]*B[j]+gamma[2]*C[j]+gamma[3]*B[j]*C[j]) + (1-A[j])*gamma[4]
              }
              
              ####### Sampling model
              for (k in 1:length(nTrials)) {
                  # Person-by-condition parameters for DM parameters
                  bound[k] ~ dgamma(2,1)
                  drift[k] ~ dnorm(drift_pred[cond[k]],drift_lambda)
          
                  # Forward equations from EZ Diffusion
                  ey[k]  = exp(-bound[k] * drift[k])
                  Pc[k]  = 1 / (1 + ey[k])
                  PRT[k] = 2 * pow(drift[k], 3) / bound[k] * pow(ey[k] + 1, 2) / (2 * -bound[k] * 
                           drift[k] * ey[k] - ey[k] * ey[k] + 1)
                  MDT[k] = (bound[k] / (2 * drift[k])) * (1 - ey[k]) / (1 + ey[k])
                  MRT[k] = MDT[k] + nondt
          
                  # Sampling distributions for summary statistics
                  correct[k] ~ dbin(Pc[k], nTrials[k])
                  varRT[k]   ~ dnorm(1/PRT[k], 0.5*(nTrials[k]-1) * PRT[k] * PRT[k])
                  meanRT[k]  ~ dnorm(MRT[k], PRT[k] * nTrials[k])
                }
    }", modelFile)
```


# JAGS

### Specify JAGS setup

```{r}
set.seed(seed)

# General setup
n.chains  <- 4;      n.iter    <- 2500
n.burnin  <- 250;    n.thin    <- 1

# Pass data to JAGS
data_toJAGS <- list("nTrials"  =  ezdata$nTrials,
                    "meanRT"   =  ezdata$meanRT,
                    "varRT"    =  ezdata$varRT,
                    "correct"  =  ezdata$score,
                    "cond"     =  ezdata$cond,
                    "A" = A, "B" = B, "C" = C)

# Specify parameters to keep track of
parameters <- c('gamma', 'drift_mu', 'drift_lambda', 'drift_sigma', 'drift_pred',
                'drift','bound', 'nondt', "Pc", "PRT", "MRT")

# Prepare initial values
myinits <- rep(list(list()), n.chains)
for(i in 1:n.chains){
    myinits[[i]] <- list(drift = rnorm(nrow(ezdata),0,1))
}
```

### Run JAGS

```{r}
set.seed(seed)

start <- Sys.time()
samples <- jags(data=data_toJAGS,
                parameters.to.save=parameters,
                model=modelFile,
                n.chains=n.chains,  n.iter=1000,
                n.burnin=100,  n.thin=n.thin,
                DIC=T, inits=myinits)
end <- Sys.time()
```

```{r, echo=FALSE}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
# This function calculates the R-hat convergence diagnostic
#
# R-hat measures the convergence of MCMC chains by comparing the variance between
# chains to the variance within chains. Values close to 1.0 indicate good convergence.
# Generally, we consider values below 1.05 to be acceptable.
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
getRhat <- function(posterior_chains, n.chains=NA) {
        # Ensure the input is a matrix
        # If a vector is provided, reshape it into a matrix with n.chains columns
        if (is.vector(posterior_chains)) {
            if(is.na(n.chains)){
                  stop("Please specify the number of chains") 
            }else{
              # Calculate iterations per chain and reshape the vector into a matrix
              n.iter <- length(posterior_chains)/n.chains
              # We assume that chains had been stacked in the vector
              posterior_chains <- matrix(posterior_chains, ncol=n.chains, nrow = n.iter, byrow = FALSE)
            }
        }else{
            # Get dimensions of the posterior chains matrix
            n.iter <- nrow(posterior_chains)  # Number of iterations per chain
            n.chains <- ncol(posterior_chains)  # Number of chains
        }
        
        # Step 1: Compute the mean of each chain
        chainMean <- apply(posterior_chains, 2, mean)
        
        # Step 2: Compute the mean of the chain means
        overall_mean <- mean(chainMean)
        
        # Step 3: Compute between-chain variance (B)
        B <- n.iter * var(chainMean)
        
        # Step 4: Compute within-chain variances (W)
        chainVar <- apply(posterior_chains, 2, var)

        # Step 5: Compute the mean of the within-chain variances
        W <- mean(chainVar)
        
        # Step 6: Estimate the marginal posterior variance 
        Z <- ((n.iter - 1) / n.iter) * W + (1 / n.iter) * B
        
        # Step 7: Compute R-hat
        Rhat <- sqrt(Z / W)
  
  return(Rhat)
}
```


```{r, echo=FALSE}
rhats <- apply(samples$BUGSoutput$sims.array,3,getRhat)
rule <- 1.05
bad.Rhat <- which(rhats>rule)
test.rhat <- length(bad.Rhat) > 0
  if(test.rhat){
          par(mfrow=c(1,1))
          which.are.bad.Rhats <- names(bad.Rhat)
          hist(rhats, breaks = 50)
          abline(v=rule, col="red", lty=2)
          legend("top",paste("Rhat > ",rule," | ",
                             (round(nrow(bad.Rhat)/(length(as.vector(rhats))),5))*100,
                             "% of chains | ", length(which.are.bad.Rhats), " chains", sep=""), lty=2, col="red", cex=0.4)
          table(which.are.bad.Rhats)
  }else{      paste("No Rhat greater than ", rule, sep="")       }
```


### Extract posterior samples

```{r}
##### Drift rate parameters
# Recovered drift rates
drift <- samples$BUGSoutput$sims.list$drift
# Regression coefficients
mu <- samples$BUGSoutput$sims.list$drift_mu
gamma <- samples$BUGSoutput$sims.list$gamma
# Fitted values / Predicted drift rates
drift_pred <- samples$BUGSoutput$sims.list$drift_pred

##### Summary statistics computed from the recovered drift and boundary
Pc   <- samples$BUGSoutput$sims.list$Pc
PRT  <- samples$BUGSoutput$sims.list$PRT
MRT  <- samples$BUGSoutput$sims.list$MRT
```

```{r, echo=FALSE}
# Custom function to select colors
myCol <- function(r,g,b,sub,alpha=1){
       rgb(r[sub]/255,g[sub]/255,b[sub]/255,alpha)
}

# Mu coefficient
r <- matrix(NA, ncol=5,nrow=9)
g <- matrix(NA, ncol=5,nrow=9)
b <- matrix(NA, ncol=5,nrow=9)

# Mu coefficient - neutral scale of grays (intercept)
r[,1] <- round(seq(180,220, length.out=9),0)
g[,1] <- round(seq(180,220, length.out=9),0)
b[,1] <- round(seq(180,220, length.out=9),0)

# Gamma 1 coefficient - warm amber/gold (quantitative vs qualitative change)
r[,2] <- round(seq(230,255, length.out=9),0)
g[,2] <- round(seq(170,210, length.out=9),0)
b[,2] <- round(seq(90,130, length.out=9),0)

# Gamma 2 coefficient - muted burgundy/wine (concavity vs convexity)
r[,3] <- round(seq(150,190, length.out=9),0)
g[,3] <- round(seq(60,90, length.out=9),0)
b[,3] <- round(seq(80,110, length.out=9),0)

# Gamma 3 coefficient - rusty terracotta (interaction effect)
r[,4] <- round(seq(200,230, length.out=9),0)
g[,4] <- round(seq(100,130, length.out=9),0)
b[,4] <- round(seq(70,100, length.out=9),0)

# Gamma 4 coefficient - steel blue-gray (change/no change)
r[,5] <- round(seq(80,120, length.out=9),0)
g[,5] <- round(seq(90,130, length.out=9),0)
b[,5] <- round(seq(100,140, length.out=9),0)
```

# Results

## Bayes Factors!

```{r}
epsilon <- 0.1
prior_constant <- pnorm(epsilon) - pnorm(-epsilon)
for(i in 1:3){
    this.gamma <- gamma[,i]
    post_mass <- mean(this.gamma > -epsilon & this.gamma < epsilon)
    this.BF <- prior_constant/post_mass
    this.BF[post_mass==0] <- 0
    cat("The B.F. for gamma", i, " in favor of an effect is", this.BF, ".", sep="")
    if(this.BF < 1){
      cat(" Evidence in favor of the null effect!\n")
    } else if (this.BF < 1.2){
      cat(" Weak evidence in favor of the effect!\n")
    } else if (this.BF < 5){
      cat(" Moderate evidence in favor of the effect!\n")
    } else {
      cat(" Strong evidence in favor of the effect!\n")
    }
}
```

## Drift predicted per condition

```{r, echo=FALSE}
source(here("src", "plot_VerticalHist.R"))
driftPred <- drift_pred[,1:4]
colnames(driftPred) <- c("QualConvex","QuantConvex","QualConcav","QuantConcav")

makePlot = function(data, binWidth = 0.1){
    binStarts <- c(0.9,1.1,1.9,2.1)
    binMids <- binStarts + binWidth / 2
    
    means <- apply(data, 2, mean)
    CI <- apply(data, 2, quantile, prob=c(0.025,0.975))
    
    DOYrange <- range(data)
    ## Get the histogram obects
    histList <- apply( data, 2, function(x, hCol) hist(x, plot = FALSE))
    
    ## Plotting
    axisCol <- "gray30"
    xlim <- c(0.5,2.5)
    ylim <- c(-1.2,2.1)
    xlabs <- c("Change in Convexity", "Change in Concavity")
    fillCol <- c("#E27D72", "#7F2E2E", "#E27D72", "#7F2E2E")
    CIcolor <- rep("#CAC7DA",4)
    
    plot(c(0, 5), DOYrange, type = "n", xlim=xlim, ylim=ylim,
         ann = FALSE, axes = FALSE, xaxs = "i", yaxs = "i")
    axis(1, 1:2, xlabs, cex.axis = 1.2, col = NA, line=-0.5, f=1)
    mtext(side = 1, outer = F, line = 2.5, "Change type", cex = 1.5, f=2)
    y.seq = format(round(seq(ylim[1],ylim[2],length.out=9),digits = 1), nsmall = 1)
    axis(2, cex.axis = 0.95, las = 1, line = -.7, col = "white", tck = 0,
         at = y.seq, labels = y.seq, las=2)
    mtext(side = 2, outer = F, line = 2, expression(paste(nu^pred)), cex = 1.2)
    box(bty = "L", col = axisCol)
    
    biggestDensity <- max(unlist(lapply(histList, function(h){max(h[[4]])})))
    xscale <- binWidth * .9 / biggestDensity
    
    ## Plot the histograms
    for (i in 1:4) {
      X <- binStarts[i]
      VerticalHist(x = X, xscale = xscale, 
                   xwidth = binWidth, 
                   hist= histList[[i]], 
                   fillCol = fillCol[i])
      points(X, means[i], pch=18, cex=1.2)
      lines(x=c(X-0.05, X+0.05), y=c(means[i],means[i]), lwd=2)
    }
    lines(binStarts[c(1,3)], means[c(1,3)], lwd=1, lty=2)
    lines(binStarts[c(2,4)], means[c(2,4)], lwd=1, lty=2)
    legend(0.5,1.9, c("Qualitative change", "Quantitative change"), col=c("#E27D72", "#7F2E2E"), pch=15, bty = "n", cex=1.2)
    text(0.7,2,"Change quality", cex=1.5, f=2)

}

makePlot(driftPred)
```

## Posterior regression coefficients

```{r, echo=FALSE}
layout(mat = matrix(c(1,1,2,2,3,3,0,4,4,5,5,0), nrow = 2, byrow = TRUE))
par(pty="m", mai=c(0.45,0.5,0.25,0), oma= c(0,0,1,1.5))

curve.gamma1 <- myCol(r[,2],g[,2],b[,2],5,0.5)
line.gamma1  <- myCol(r[,2],g[,2],b[,2],2,1)
curve.gamma2 <- myCol(r[,3],g[,3],b[,3],5,0.5)
line.gamma2  <- myCol(r[,3],g[,3],b[,3],2,1)
curve.gamma3 <- myCol(r[,4],g[,4],b[,4],5,0.5)
line.gamma3  <- myCol(r[,4],g[,4],b[,4],2,1)
curve.gamma4 <- myCol(r[,5],g[,5],b[,5],5,0.5)
line.gamma4  <- myCol(r[,5],g[,5],b[,5],2,1)
curve.mu <- myCol(r[,1],g[,1],b[,1],5,0.5)
line.mu  <- myCol(r[,1],g[,1],b[,1],2,1)

title.cex <- 1
title.line <- 1.3
subtitle.cex <- 0.75
subtitle.line <- -0.2
max.Y <- c(max(density(gamma[,1])$y,density(gamma[,2])$y,density(gamma[,3])$y))
hist(gamma[,1], freq = FALSE, breaks = 50, col=curve.gamma1, border = curve.gamma1, 
     ann=F, axes = T, ylim = c(0, max.Y), xlim=c(-1.5,1.5))
lines(density(gamma[,1]), lwd=4, col=line.gamma1)
mtext("Quantitative change", cex=title.cex, f=2, side=3, line=title.line)
mtext("(Main effect)", cex=subtitle.cex, f=2, side=3, line=subtitle.line, col="gray30")
mtext("Density",side=2,line=2.15, cex=0.8)
mtext(expression(paste(gamma[1])),side=1,line=2.5, cex=1)
abline(v=0,lty=2,col="gray50")

hist(gamma[,2], freq = FALSE, breaks = 50, col=curve.gamma2, border = curve.gamma2,
     ann=F, axes = T, ylim = c(0, max.Y), xlim=c(-1.5,1.55))
lines(density(gamma[,2]), lwd=4, col=line.gamma2)
mtext("Change in Concavity", cex=title.cex, f=2, side=3, line=title.line)
mtext("(Main effect)", cex=subtitle.cex, f=2, side=3, line=subtitle.line, col="gray30")
mtext(expression(paste(gamma[2])),side=1,line=2.5, cex=1)
abline(v=0,lty=2,col="gray50")

hist(gamma[,3], freq = FALSE, breaks = 50, col=curve.gamma3, border = curve.gamma3, 
     ann=F, axes = T, ylim = c(0, max.Y), xlim=c(-1.5,1.5))
lines(density(gamma[,3]), lwd=4, col=line.gamma3)
mtext("Quantitative change in Concavity", cex=title.cex, f=2, side=3, line=title.line)
mtext("(Interaction effect)", cex=subtitle.cex, f=2, side=3, line=subtitle.line, col="gray30")
mtext(expression(paste(gamma[3])),side=1,line=2.5, cex=1)
abline(v=0,lty=2,col="gray50")

max.Y <- c(max(density(gamma[,4])$y,density(mu)$y))+0.1

hist(gamma[,4], freq = FALSE, breaks = 50, col=curve.gamma4, border = curve.gamma4, 
     ann=F, axes = T, ylim=c(0, max.Y))
lines(density(gamma[,4]), lwd=4, col=line.gamma4)
mtext("Change NOT occuring", cex=title.cex, f=2, side=3, line=title.line)
mtext("(Main effect)", cex=subtitle.cex, f=2, side=3, line=subtitle.line, col="gray30")
mtext("Density",side=2,line=2.15, cex=0.8)
mtext(expression(paste(gamma[4])),side=1,line=2.5, cex=1)
abline(v=0,lty=2,col="gray50")

hist(mu, freq = FALSE, breaks = 50, col=curve.mu, border = curve.mu, ann=F, 
     axes = T, ylim=c(0, max.Y))
lines(density(mu), lwd=4, col=line.mu)
mtext("Qualitative change in Convexity", cex=title.cex, f=2, side=3, line=title.line)
mtext("(Intercept; Baseline drift)", cex=subtitle.cex, f=2, side=3, line=subtitle.line, col="gray30")
mtext(expression(paste(mu)),side=1,line=2.5, cex=1)
abline(v=0,lty=2,col="gray50")
```



## Posterior predictive checks

```{r, echo=FALSE}
# Number of trials per condition
nTrials <- ezdata$nTrials
# Number of posterior samples
n <- nrow(Pc) 
# Number of conditions
J <- ncol(Pc)
# Empty matrices to store posterior predictions
pp_accRate <- matrix(NA, nrow=n, ncol=J)
pp_meanRT  <- matrix(NA, nrow=n, ncol=J)
pp_varRT   <- matrix(NA, nrow=n, ncol=J)
# Obtain posterior predictions using sampling distributions
#        and the summary statistics derived from the recovered
#        drift and boundary parameters
for(i in 1:J){
  correct  <-  rbinom(n,nTrials[i],Pc[,i])
  pp_accRate[,i] <- correct/nTrials[i]
  pp_varRT[,i]   <- rnorm(n,1/PRT[,i], sqrt(2/((nTrials[i]-1) * PRT[,i] * PRT[,i])))
  pp_meanRT[,i]  <- rnorm(n,MRT[,i],sqrt(1/(PRT[,i]*nTrials[i])))
}
```

```{r, echo=FALSE}
#####################
#   Accuracy rate   #
#####################
iter <- nrow(pp_accRate)
jitter.x <- runif(iter,-0.12,0.12)

base.recangle.bg <- "#F2EFE9"    # Light cream/parchment color
base.recangle.border <- "#C8B8A9" # Warm taupe/light brown

# Initialize plotting space
layout(mat = matrix(c(1,1,2,2,3,3,
                      0,4,4,5,5,0), nrow = 2, byrow = TRUE))
par(pty="m", mai=c(0.45,0.5,0.25,0), oma= c(0,0,5,1.5))

plot_ppAcc <- function(pp_accRate, ezdata){
     for(k in 1:5){
          plot(4.5, 10, col="white", ylim=c(0,1), xlim=c(0.5,9.5),ann=F,axes=F)
          axis(1,seq(1,9,length.out=9),paste("i =",1:9), line=-0.65)
          axis(2,seq(0,1,0.1), seq(0,1,0.1),las=1)
          mtext("Participant",1,line=1.7,cex=0.8)
          for(i in 1:9){
            this.Y <- pp_accRate[,seq(k,ncol(pp_accRate),5)[i]]
            CI <- quantile(this.Y, probs = c(0.025,0.975))
            polygon(x=c(i-0.4,i+0.4,i+0.4,i-0.4),y=c(CI[1],CI[1],CI[2],CI[2]), col=base.recangle.bg, border=base.recangle.border)
            points(i+jitter.x,this.Y, col=myCol(r[,k],g[,k],b[,k],i,0.05), pch=16, cex=0.8)
            points(i, ezdata$acc_rate[which(ezdata$cond==k)][i], pch=8)
          }
          mtext(paste("Condition", k), f=2, line=1.5, cex=0.9)
          if(k==1){mtext("Qualitative change in Convexity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==2){mtext("Quantitative change in Convexity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==3){mtext("Qualitative change in Concavity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==4){mtext("Quantitative change in Concavity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==5){mtext("No change at all", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==1|k==4){ mtext("Accuracy rate", 2, line=2.5, cex=0.8) }
          mtext("Accuracy rate per condition per participant",3,outer=TRUE, f=2, line=2, cex=1.8)
     }
}

plot_ppAcc(pp_accRate, ezdata)
```



```{r, echo=FALSE}
################
#   Mean RT    #
################
iter <- nrow(pp_varRT)
jitter.x <- runif(iter,-0.12,0.12)

# Initialize plotting space
layout(mat = matrix(c(1,1,2,2,3,3,
                      0,4,4,5,5,0), nrow = 2, byrow = TRUE))
par(pty="m", mai=c(0.45,0.5,0.25,0), oma= c(0,0,5,1.5))

plot_ppMeanRT <- function(pp_meanRT, ezdata){
     minY <- min(pp_meanRT)
     maxY <- max(pp_meanRT)
     for(k in 1:5){
          plot(4.5, 10, col="white", ylim=c(minY,maxY), xlim=c(0.5,9.5),ann=F,axes=F)
          axis(1,seq(1,9,length.out=9),paste("i =",1:9), line=-0.65)
          axis(2,seq(minY,maxY,length.out=10), round(seq(minY,maxY,length.out=10),1),las=1)
          mtext("Participant",1,line=1.7,cex=0.8)
          for(i in 1:9){
            this.Y <- pp_meanRT[,seq(k,ncol(pp_meanRT),5)[i]]
            CI <- quantile(this.Y, probs = c(0.025,0.975))
            polygon(x=c(i-0.4,i+0.4,i+0.4,i-0.4),y=c(CI[1],CI[1],CI[2],CI[2]), col=base.recangle.bg, border=base.recangle.border)
            points(i+jitter.x,this.Y, col=myCol(r[,k],g[,k],b[,k],i,0.05), pch=16, cex=0.8)
            points(i, ezdata$meanRT[which(ezdata$cond==k)][i], pch=8)
          }          
          mtext(paste("Condition", k), f=2, line=1.5, cex=0.9)
          if(k==1){mtext("Qualitative change in Convexity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==2){mtext("Quantitative change in Convexity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==3){mtext("Qualitative change in Concavity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==4){mtext("Quantitative change in Concavity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==5){mtext("No change at all", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==1|k==4){ mtext("Mean RT (secs)", 2, line=2.5, cex=0.8) }
          mtext("Mean RT per condition per participant",3,outer=TRUE, f=2, line=2, cex=1.8)
     }
}

plot_ppMeanRT(pp_meanRT, ezdata)
```



```{r, echo=FALSE}
################
#   Variance RT    #
################
iter <- nrow(pp_meanRT)
jitter.x <- runif(iter,-0.12,0.12)

# Initialize plotting space
layout(mat = matrix(c(1,1,2,2,3,3,
                      0,4,4,5,5,0), nrow = 2, byrow = TRUE))
par(pty="m", mai=c(0.45,0.5,0.25,0), oma= c(0,0,5,1.5))

plot_ppvarRT <- function(pp_varRT, ezdata){
     ppl_varRT <- log(pp_varRT)
     minY <- min(ppl_varRT)
     maxY <- max(ppl_varRT)
     for(k in 1:5){
          plot(4.5, 10, col="white", ylim=c(minY,maxY), xlim=c(0.5,9.5),ann=F,axes=F)
          axis(1,seq(1,9,length.out=9),paste("i =",1:9), line=-0.65)
          axis(2,seq(minY,maxY,length.out=10), round(seq(minY,maxY,length.out=10),1),las=1)
          mtext("Participant",1,line=1.7,cex=0.8)
          for(i in 1:9){
            this.Y <- ppl_varRT[,seq(k,ncol(ppl_varRT),5)[i]]
            CI <- quantile(this.Y, probs = c(0.025,0.975))
            polygon(x=c(i-0.4,i+0.4,i+0.4,i-0.4),y=c(CI[1],CI[1],CI[2],CI[2]), col=base.recangle.bg, border=base.recangle.border)
            points(i+jitter.x,this.Y, col=myCol(r[,k],g[,k],b[,k],i,0.05), pch=16, cex=0.8)
            points(i, log(ezdata$varRT[which(ezdata$cond==k)][i]), pch=8)
          }
          mtext(paste("Condition", k), f=2, line=1.5, cex=0.9)
          if(k==1){mtext("Qualitative change in Convexity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==2){mtext("Quantitative change in Convexity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==3){mtext("Qualitative change in Concavity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==4){mtext("Quantitative change in Concavity", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==5){mtext("No change at all", f=2, line=.5, cex=0.7, col="gray35")}
          if(k==1|k==4){ mtext("RT variance (log-scale)", 2, line=2.5, cex=0.8) }
          mtext("RT variance per condition per participant",3,outer=TRUE, f=2, line=2, cex=1.8)
     }
}

plot_ppvarRT(pp_varRT, ezdata)
```



