
@article{rouder_lognormal_2015,
	title = {The {Lognormal} {Race}: {A} {Cognitive}-{Process} {Model} of {Choice} and {Latency} with {Desirable} {Psychometric} {Properties}},
	volume = {80},
	issn = {1860-0980},
	shorttitle = {The {Lognormal} {Race}},
	url = {https://doi.org/10.1007/s11336-013-9396-3},
	doi = {10.1007/s11336-013-9396-3},
	abstract = {We present a cognitive process model of response choice and response time performance data that has excellent psychometric properties and may be used in a wide variety of contexts. In the model there is an accumulator associated with each response option. These accumulators have bounds, and the first accumulator to reach its bound determines the response time and response choice. The times at which accumulator reaches its bound is assumed to be lognormally distributed, hence the model is race or minima process among lognormal variables. A key property of the model is that it is relatively straightforward to place a wide variety of models on the logarithm of these finishing times including linear models, structural equation models, autoregressive models, growth-curve models, etc. Consequently, the model has excellent statistical and psychometric properties and can be used in a wide range of contexts, from laboratory experiments to high-stakes testing, to assess performance. We provide a Bayesian hierarchical analysis of the model, and illustrate its flexibility with an application in testing and one in lexical decision making, a reading skill.},
	language = {en},
	number = {2},
	urldate = {2023-11-21},
	journal = {Psychometrika},
	author = {Rouder, Jeffrey N. and Province, Jordan M. and Morey, Richard D. and Gomez, Pablo and Heathcote, Andrew},
	month = jun,
	year = {2015},
	keywords = {cognitive psychometrics, race models, response-times models},
	pages = {491--513},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/GEZUJYMT/Rouder et al. - 2015 - The Lognormal Race A Cognitive-Process Model of C.pdf:application/pdf},
}

@article{ratcliff_modeling_1998,
	title = {Modeling {Response} {Times} for {Two}-{Choice} {Decisions}},
	volume = {9},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/1467-9280.00067},
	doi = {10.1111/1467-9280.00067},
	abstract = {The diffusion model for two-choice real-time decisions is applied to four psychophysical tasks. The model reveals how stimulus information guides decisions and shows how the information is processed through time to yield sometimes correct and sometimes incorrect decisions. Rapid two-choice decisions yield multiple empirical measures: response times for correct and error responses, the probabilities of correct and error responses, and a variety of interactions between accuracy and response time that depend on instructions and task difficulty. The diffusion model can explain all these aspects of the data for the four experiments we present. The model correctly accounts for error response times, something previous models have failed to do. Variability within the decision process explains how errors are made, and variability across trials correctly predicts when errors are faster than correct responses and when they are slower.},
	number = {5},
	urldate = {2023-11-20},
	journal = {Psychological Science},
	author = {Ratcliff, Roger and Rouder, Jeffrey N.},
	month = sep,
	year = {1998},
	note = {Publisher: SAGE Publications Inc},
	pages = {347--356},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/647PB73F/Ratcliff and Rouder - 1998 - Modeling Response Times for Two-Choice Decisions.pdf:application/pdf},
}

@article{ratcliff_theory_1978,
	title = {A theory of memory retrieval},
	volume = {85},
	issn = {1939-1471},
	doi = {10.1037/0033-295X.85.2.59},
	abstract = {Develops a theory of memory retrieval and shows that it applies over a range of experimental paradigms. Access to memory traces is viewed in terms of a resonance metaphor. The probe item evokes the search set on the basis of probe–memory item relatedness, just as a ringing tuning fork evokes sympathetic vibrations in other tuning forks. Evidence is accumulated in parallel from each probe–memory item comparison, and each comparison is modeled by a continuous random walk process. In item recognition, the decision process is self-terminating on matching comparisons and exhaustive on nonmatching comparisons. The mathematical model produces predictions about accuracy, mean reaction time, error latency, and reaction time distributions that are in good accord with data from 2 experiments conducted with 6 undergraduates. The theory is applied to 4 item recognition paradigms (Sternberg, prememorized list, study–test, and continuous) and to speed–accuracy paradigms; results are found to provide a basis for comparison of these paradigms. It is noted that neural network models can be interfaced to the retrieval theory with little difficulty and that semantic memory models may benefit from such a retrieval scheme. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Review},
	author = {Ratcliff, Roger},
	year = {1978},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Memory, Theories},
	pages = {59--108},
	file = {Snapshot:/home/babymagikarp/Zotero/storage/MJ8PK489/1978-30970-001.html:text/html},
}

@article{vandekerckhove_hierarchical_2011,
	title = {Hierarchical diffusion models for two-choice response times},
	volume = {16},
	issn = {1939-1463},
	doi = {10.1037/a0021765},
	abstract = {Two-choice response times are a common type of data, and much research has been devoted to the development of process models for such data. However, the practical application of these models is notoriously complicated, and flexible methods are largely nonexistent. We combine a popular model for choice response times—the Wiener diffusion process—with techniques from psychometrics in order to construct a hierarchical diffusion model. Chief among these techniques is the application of random effects, with which we allow for unexplained variability among participants, items, or other experimental units. These techniques lead to a modeling framework that is highly flexible and easy to work with. Among the many novel models this statistical framework provides are a multilevel diffusion model, regression diffusion models, and a large family of explanatory diffusion models. We provide examples and the necessary computer code. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Methods},
	author = {Vandekerckhove, Joachim and Tuerlinckx, Francis and Lee, Michael D.},
	year = {2011},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Reaction Time, Models, Psychometrics},
	pages = {44--62},
	file = {Full Text:/home/babymagikarp/Zotero/storage/JRCVYBKC/Vandekerckhove et al. - 2011 - Hierarchical diffusion models for two-choice respo.pdf:application/pdf;Snapshot:/home/babymagikarp/Zotero/storage/THDH7GZA/2011-02224-001.html:text/html},
}

@article{van_ravenzwaaij_ez_2017,
	title = {The {EZ} diffusion model provides a powerful test of simple empirical effects},
	volume = {24},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-016-1081-y},
	doi = {10.3758/s13423-016-1081-y},
	abstract = {Over the last four decades, sequential accumulation models for choice response times have spread through cognitive psychology like wildfire. The most popular style of accumulator model is the diffusion model (Ratcliff Psychological Review, 85, 59–108, 1978), which has been shown to account for data from a wide range of paradigms, including perceptual discrimination, letter identification, lexical decision, recognition memory, and signal detection. Since its original inception, the model has become increasingly complex in order to account for subtle, but reliable, data patterns. The additional complexity of the diffusion model renders it a tool that is only for experts. In response, Wagenmakers et al. (Psychonomic Bulletin \& Review, 14, 3–22, 2007) proposed that researchers could use a more basic version of the diffusion model, the EZ diffusion. Here, we simulate experimental effects on data generated from the full diffusion model and compare the power of the full diffusion model and EZ diffusion to detect those effects. We show that the EZ diffusion model, by virtue of its relative simplicity, will be sometimes better able to detect experimental effects than the data–generating full diffusion model.},
	language = {en},
	number = {2},
	urldate = {2023-11-20},
	journal = {Psychonomic Bulletin \& Review},
	author = {van Ravenzwaaij, Don and Donkin, Chris and Vandekerckhove, Joachim},
	month = apr,
	year = {2017},
	keywords = {Model complexity, Power, Response time analysis, Sequential accumulator models},
	pages = {547--556},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/8TQS6IIY/van Ravenzwaaij et al. - 2017 - The EZ diffusion model provides a powerful test of.pdf:application/pdf},
}

@article{wagenmakers_ez-diffusion_2007,
	title = {An {EZ}-diffusion model for response time and accuracy},
	volume = {14},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/BF03194023},
	doi = {10.3758/BF03194023},
	abstract = {The EZ-diffusion model for two-choice response time tasks takes mean response time, the variance of response time, and response accuracy as inputs. The model transforms these data via three simple equations to produce unique values for the quality of information, response conservativeness, and nondecision time. This transformation of observed data in terms of unobserved variables addresses the speed—accuracy trade-off and allows an unambiguous quantification of performance differences in two-choice response time tasks. The EZ-diffusion model can be applied to data-sparse situations to facilitate individual subject analysis. We studied the performance of the EZ-diffusion model in terms of parameter recovery and robustness against misspecification by using Monte Carlo simulations. The EZ model was also applied to a real-world data set.},
	language = {en},
	number = {1},
	urldate = {2023-11-20},
	journal = {Psychonomic Bulletin \& Review},
	author = {Wagenmakers, Eric-Jan and Van Der Maas, Han L. J. and Grasman, Raoul P. P. P.},
	month = feb,
	year = {2007},
	keywords = {Boundary Separation, Diffusion Model, Drift Rate, Error Response, Parameter Recovery},
	pages = {3--22},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/96BRDCGS/Wagenmakers et al. - 2007 - An EZ-diffusion model for response time and accura.pdf:application/pdf},
}

@article{noorani_later_2016,
	title = {The {LATER} model of reaction time and decision},
	volume = {64},
	issn = {01497634},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763415301226},
	doi = {10.1016/j.neubiorev.2016.02.018},
	language = {en},
	urldate = {2023-12-15},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Noorani, Imran and Carpenter, R.H.S.},
	month = may,
	year = {2016},
	pages = {229--251},
	file = {Noorani and Carpenter - 2016 - The LATER model of reaction time and decision.pdf:/home/babymagikarp/Zotero/storage/5Y4R2GT7/Noorani and Carpenter - 2016 - The LATER model of reaction time and decision.pdf:application/pdf},
}

@article{ratcliff_comparison_2004,
	title = {A {Comparison} of {Sequential} {Sampling} {Models} for {Two}-{Choice} {Reaction} {Time}},
	volume = {111},
	issn = {1939-1471},
	doi = {10.1037/0033-295X.111.2.333},
	abstract = {The authors evaluated 4 sequential sampling models for 2-choice decisions--the Wiener diffusion, Ornstein-Uhlenbeck (OU) diffusion, accumulator, and Poisson counter models--by fitting them to the response time (RT) distributions and accuracy data from 3 experiments. Each of the models was augmented with assumptions of variability across trials in the rate of accumulation of evidence from stimuli, the values of response criteria, and the value of base RT across trials. Although there was substantial model mimicry, empirical conditions were identified under which the models make discriminably different predictions. The best accounts of the data were provided by the Wiener diffusion model, the OU model with small-to-moderate decay, and the accumulator model with long-tailed (exponential) distributions of criteria, although the last was unable to produce error RTs shorter than correct RTs. The relationship between these models and 3 recent, neurally inspired models was also examined. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Review},
	author = {Ratcliff, Roger and Smith, Philip L.},
	year = {2004},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Reaction Time, Decision Making, Models, Sampling (Experimental), Stimulus Parameters},
	pages = {333--367},
	file = {Accepted Version:/home/babymagikarp/Zotero/storage/A8JQDTGZ/Ratcliff and Smith - 2004 - A Comparison of Sequential Sampling Models for Two.pdf:application/pdf;Snapshot:/home/babymagikarp/Zotero/storage/F3Y4LD2P/2004-12248-003.html:text/html},
}

@incollection{lee_bayesian_2018,
	title = {Bayesian methods in cognitive modeling},
	volume = {5},
	booktitle = {The {Stevens}’ handbook of experimental psychology and cognitive neuroscience},
	author = {Lee, M. D.},
	year = {2018},
	pages = {37--84},
}

@article{forstmann_sequential_2016,
	title = {Sequential {Sampling} {Models} in {Cognitive} {Neuroscience}: {Advantages}, {Applications}, and {Extensions}},
	volume = {67},
	shorttitle = {Sequential {Sampling} {Models} in {Cognitive} {Neuroscience}},
	url = {https://doi.org/10.1146/annurev-psych-122414-033645},
	doi = {10.1146/annurev-psych-122414-033645},
	abstract = {Sequential sampling models assume that people make speeded decisions by gradually accumulating noisy information until a threshold of evidence is reached. In cognitive science, one such model—the diffusion decision model—is now regularly used to decompose task performance into underlying processes such as the quality of information processing, response caution, and a priori bias. In the cognitive neurosciences, the diffusion decision model has recently been adopted as a quantitative tool to study the neural basis of decision making under time pressure. We present a selective overview of several recent applications and extensions of the diffusion decision model in the cognitive neurosciences.},
	number = {1},
	urldate = {2023-12-15},
	journal = {Annual Review of Psychology},
	author = {Forstmann, B.U. and Ratcliff, R. and Wagenmakers, E.-J.},
	year = {2016},
	pmid = {26393872},
	note = {\_eprint: https://doi.org/10.1146/annurev-psych-122414-033645},
	keywords = {decision making, diffusion decision model, drift rate, information accumulation, response time, speed-accuracy trade-off},
	pages = {641--666},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/S3IL6QAY/Forstmann et al. - 2016 - Sequential Sampling Models in Cognitive Neuroscien.pdf:application/pdf},
}

@article{ratcliff_estimating_2002,
	title = {Estimating parameters of the diffusion model: {Approaches} to dealing with contaminant reaction times and parameter variability},
	volume = {9},
	issn = {1531-5320},
	shorttitle = {Estimating parameters of the diffusion model},
	url = {https://doi.org/10.3758/BF03196302},
	doi = {10.3758/BF03196302},
	abstract = {Three methods for fitting the diffusion model (Ratcliff, 1978) to experimental data are examined. Sets of simulated data were generated with known parameter values, and from fits of the model, we found that the maximum likelihood method was better than the chi-square and weighted least squares methods by criteria of bias in the parameters relative to the parameter values used to generate the data and standard deviations in the parameter estimates. The standard deviations in the parameter values can be used as measures of the variability in parameter estimates from fits to experimental data. We introduced contaminant reaction times and variability into the other components of processing besides the decision process and found that the maximum likelihood and chi-square methods failed, sometimes dramatically. But the weighted least squares method was robust to these two factors. We then present results from modifications of the maximum likelihood and chi-square methods, in which these factors are explicitly modeled, and show that the parameter values of the diffusion model are recovered well. We argue that explicit modeling is an important method for addressing contaminants and variability in nondecision processes and that it can be applied in any theoretical approach to modeling reaction time.},
	language = {en},
	number = {3},
	urldate = {2023-12-16},
	journal = {Psychonomic Bulletin \& Review},
	author = {Ratcliff, Roger and Tuerlinckx, Francis},
	month = sep,
	year = {2002},
	keywords = {Reaction Time, Diffusion Model, Drift Rate, Error Response, Maximum Likelihood Method},
	pages = {438--481},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/PIF9DAAC/Ratcliff and Tuerlinckx - 2002 - Estimating parameters of the diffusion model Appr.pdf:application/pdf},
}

@article{voss_diffusion_2013,
	title = {Diffusion {Models} in {Experimental} {Psychology}: {A} {Practical} {Introduction}},
	volume = {60},
	issn = {1618-3169, 2190-5142},
	shorttitle = {Diffusion {Models} in {Experimental} {Psychology}},
	url = {https://econtent.hogrefe.com/doi/10.1027/1618-3169/a000218},
	doi = {10.1027/1618-3169/a000218},
	abstract = {Stochastic diffusion models (Ratcliff, 1978) can be used to analyze response time data from binary decision tasks. They provide detailed information about cognitive processes underlying the performance in such tasks. Most importantly, different parameters are estimated from the response time distributions of correct responses and errors that map (1) the speed of information uptake, (2) the amount of information used to make a decision, (3) possible decision biases, and (4) the duration of nondecisional processes. Although this kind of model can be applied to many experimental paradigms and provides much more insight than the analysis of mean response times can, it is still rarely used in cognitive psychology. In the present paper, we provide comprehensive information on the theory of the diffusion model, as well as on practical issues that have to be considered for implementing the model.},
	language = {en},
	number = {6},
	urldate = {2023-12-22},
	journal = {Experimental Psychology},
	author = {Voss, Andreas and Nagler, Markus and Lerche, Veronika},
	month = jan,
	year = {2013},
	pages = {385--402},
	file = {Voss et al. - 2013 - Diffusion Models in Experimental Psychology A Pra.pdf:/home/babymagikarp/Zotero/storage/MUCVQL75/Voss et al. - 2013 - Diffusion Models in Experimental Psychology A Pra.pdf:application/pdf},
}

@article{wood_statistical_2010,
	title = {Statistical inference for noisy nonlinear ecological dynamic systems},
	volume = {466},
	copyright = {2010 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature09319},
	doi = {10.1038/nature09319},
	abstract = {Many ecological systems have chaotic or near-chaotic dynamics. In such cases, it is difficult to test whether the data fit particular models, because the noise makes statistical comparison with the model impossible. Simon Wood has now devised a statistical method for making such inferences, based on extracting phase-insensitive summary statistics from the raw data and comparing to data that are simulated from the model. The method is demonstrated by an application to a well-known problem: the nature of the cycles in John Nicholson's classic ecological experiments on population size in the sheep blowfly Lucilia cuprina.},
	language = {en},
	number = {7310},
	urldate = {2023-12-22},
	journal = {Nature},
	author = {Wood, Simon N.},
	month = aug,
	year = {2010},
	note = {Number: 7310
Publisher: Nature Publishing Group},
	keywords = {Ecology, Environmental sciences},
	pages = {1102--1104},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/CQ2BQVQF/Wood - 2010 - Statistical inference for noisy nonlinear ecologic.pdf:application/pdf},
}

@article{mulder_perceptual_2014,
	title = {Perceptual decision neurosciences – {A} model-based review},
	volume = {277},
	issn = {0306-4522},
	url = {https://www.sciencedirect.com/science/article/pii/S0306452214006046},
	doi = {10.1016/j.neuroscience.2014.07.031},
	language = {en-US},
	urldate = {2023-12-22},
	journal = {Neuroscience},
	author = {Mulder, M.J. and van Maanen, L. and Forstmann, B.U.},
	month = sep,
	year = {2014},
	note = {Publisher: Pergamon},
	pages = {872--884},
	file = {Snapshot:/home/babymagikarp/Zotero/storage/4J5F7TUN/S0306452214006046.html:text/html},
}

@article{enkavi_large-scale_2019,
	title = {Large-scale analysis of test–retest reliabilities of self-regulation measures},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1818430116},
	doi = {10.1073/pnas.1818430116},
	abstract = {The ability to regulate behavior in service of long-term goals is a widely studied psychological construct known as self-regulation. This wide interest is in part due to the putative relations between self-regulation and a range of real-world behaviors. Self-regulation is generally viewed as a trait, and individual differences are quantified using a diverse set of measures, including self-report surveys and behavioral tasks. Accurate characterization of individual differences requires measurement reliability, a property frequently characterized in self-report surveys, but rarely assessed in behavioral tasks. We remedy this gap by (
              i
              ) providing a comprehensive literature review on an extensive set of self-regulation measures and (
              ii
              ) empirically evaluating test–retest reliability of this battery in a new sample. We find that dependent variables (DVs) from self-report surveys of self-regulation have high test–retest reliability, while DVs derived from behavioral tasks do not. This holds both in the literature and in our sample, although the test–retest reliability estimates in the literature are highly variable. We confirm that this is due to differences in between-subject variability. We also compare different types of task DVs (e.g., model parameters vs. raw response times) in their suitability as individual difference DVs, finding that certain model parameters are as stable as raw DVs. Our results provide greater psychometric footing for the study of self-regulation and provide guidance for future studies of individual differences in this domain.},
	language = {en},
	number = {12},
	urldate = {2023-12-22},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Enkavi, A. Zeynep and Eisenberg, Ian W. and Bissett, Patrick G. and Mazza, Gina L. and MacKinnon, David P. and Marsch, Lisa A. and Poldrack, Russell A.},
	month = mar,
	year = {2019},
	pages = {5472--5477},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/XZBWPPE4/Enkavi et al. - 2019 - Large-scale analysis of test–retest reliabilities .pdf:application/pdf},
}

@article{schmiedek_individual_2007,
	title = {Individual differences in components of reaction time distributions and their relations to working memory and intelligence.},
	volume = {136},
	issn = {1939-2222, 0096-3445},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.136.3.414},
	doi = {10.1037/0096-3445.136.3.414},
	abstract = {The authors bring together approaches from cognitive and individual differences psychology to model characteristics of reaction time distributions beyond measures of central tendency. Ex-Gaussian distributions and a diffusion model approach are used to describe individuals’ reaction time data. The authors identified common latent factors for each of the 3 ex-Gaussian parameters and for 3 parameters central to the diffusion model using structural equation modeling for a battery of choice reaction tasks. These factors had differential relations to criterion constructs. Parameters reflecting the tail of the distribution (i.e., ␶ in the ex-Gaussian and drift rate in the diffusion model) were the strongest unique predictors of working memory, reasoning, and psychometric speed. Theories of controlled attention and binding are discussed as potential theoretical explanations.},
	language = {en},
	number = {3},
	urldate = {2023-12-22},
	journal = {Journal of Experimental Psychology: General},
	author = {Schmiedek, Florian and Oberauer, Klaus and Wilhelm, Oliver and Süß, Heinz-Martin and Wittmann, Werner W.},
	year = {2007},
	pages = {414--429},
	file = {Schmiedek et al. - 2007 - Individual differences in components of reaction t.pdf:/home/babymagikarp/Zotero/storage/KARHHV3Z/Schmiedek et al. - 2007 - Individual differences in components of reaction t.pdf:application/pdf},
}

@article{bitzer_perceptual_2014,
	title = {Perceptual decision making: drift-diffusion model is equivalent to a {Bayesian} model},
	volume = {8},
	issn = {1662-5161},
	shorttitle = {Perceptual decision making},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2014.00102},
	abstract = {Behavioral data obtained with perceptual decision making experiments are typically analyzed with the drift-diffusion model. This parsimonious model accumulates noisy pieces of evidence toward a decision bound to explain the accuracy and reaction times of subjects. Recently, Bayesian models have been proposed to explain how the brain extracts information from noisy input as typically presented in perceptual decision making tasks. It has long been known that the drift-diffusion model is tightly linked with such functional Bayesian models but the precise relationship of the two mechanisms was never made explicit. Using a Bayesian model, we derived the equations which relate parameter values between these models. In practice we show that this equivalence is useful when fitting multi-subject data. We further show that the Bayesian model suggests different decision variables which all predict equal responses and discuss how these may be discriminated based on neural correlates of accumulated evidence. In addition, we discuss extensions to the Bayesian model which would be difficult to derive for the drift-diffusion model. We suggest that these and other extensions may be highly useful for deriving new experiments which test novel hypotheses.},
	urldate = {2023-12-22},
	journal = {Frontiers in Human Neuroscience},
	author = {Bitzer, Sebastian and Park, Hame and Blankenburg, Felix and Kiebel, Stefan},
	year = {2014},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/RB294E5F/Bitzer et al. - 2014 - Perceptual decision making drift-diffusion model .pdf:application/pdf},
}

@article{baayen_subjects_2002,
	title = {The {Subjects} as a {Simple} {Random} {Effect} {Fallacy}: {Subject} {Variability} and {Morphological} {Family} {Effects} in the {Mental} {Lexicon}},
	volume = {81},
	issn = {0093-934X},
	shorttitle = {The {Subjects} as a {Simple} {Random} {Effect} {Fallacy}},
	url = {https://www.sciencedirect.com/science/article/pii/S0093934X01925064},
	doi = {10.1006/brln.2001.2506},
	abstract = {This is a methodological study addressing the appropriateness of standard by-subject and by-item averaging procedures for the analysis of repeated-measures designs. By means of a reanalysis of published data (Schreuder \& Baayen, 1997), using random regression models, we present a proof of existence of systematic variability between participants that is ignored in the standard psycholinguistic analytical procedures. By applying linear mixed effects modeling (Pinheiro \& Bates, 2000), we call attention to the potential lack of power of the by-subject and by-item analyses, which in this case study fail to reveal the coexistence of a facilitatory family size effect and an inhibitory family frequency effect in visual and auditory lexical processing.},
	number = {1},
	urldate = {2023-12-28},
	journal = {Brain and Language},
	author = {Baayen, R. Harald and Tweedie, Fiona J. and Schreuder, Robert},
	month = apr,
	year = {2002},
	pages = {55--65},
	file = {ScienceDirect Snapshot:/home/babymagikarp/Zotero/storage/U6M7FWHJ/S0093934X01925064.html:text/html},
}

@article{lee_modeling_2005,
	title = {Modeling individual differences in cognition},
	volume = {12},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/BF03196751},
	doi = {10.3758/BF03196751},
	abstract = {Many evaluations of cognitive models rely on data that have been averaged or aggregated across all experimental subjects, and so fail to consider the possibility of important individual differences between subjects. Other evaluations are done at the single-subject level, and so fail to benefit from the reduction of noise that data averaging or aggregation potentially provides. To overcome these weaknesses, we have developed a general approach to modeling individual differences using families of cognitive models in which different groups of subjects are identified as having different psychological behavior. Separate models with separate parameterizations are applied to each group of subjects, and Bayesian model selection is used to determine the appropriate number of groups. We evaluate this individual differences approach in a simulation study and show that it is superior in terms of the key modeling goals of prediction and understanding. We also provide two practical demonstrations of the approach, one using the ALCOVE model of category learning with data from four previously analyzed category learning experiments, the other using multidimensional scaling representational models with previously analyzed similarity data for colors. In both demonstrations, meaningful individual differences are found and the psychological models are able to account for this variation through interpretable differences in parameterization. The results highlight the potential of extending cognitive models to consider individual differences.},
	language = {en},
	number = {4},
	urldate = {2023-12-28},
	journal = {Psychonomic Bulletin \& Review},
	author = {Lee, Michael D. and Webb, Michael R.},
	month = aug,
	year = {2005},
	keywords = {Category Learning, Group Approach, Individual Approach, Model Family, Multidimensional Scaling},
	pages = {605--621},
	file = {Full Text PDF:/home/babymagikarp/Zotero/storage/938JBGB8/Lee and Webb - 2005 - Modeling individual differences in cognition.pdf:application/pdf},
}

@article{clark_language-as-fixed-effect_1973,
	title = {The language-as-fixed-effect fallacy: {A} critique of language statistics in psychological research},
	volume = {12},
	issn = {0022-5371},
	shorttitle = {The language-as-fixed-effect fallacy},
	url = {https://www.sciencedirect.com/science/article/pii/S0022537173800143},
	doi = {10.1016/S0022-5371(73)80014-3},
	abstract = {Current investigators of words, sentences, and other language materials almost never provide statistical evidence that their findings generalize beyond the specific sample of language materials they have chosen. Nevertheless, these same investigators do not hesitate to conclude that their findings are true for language in general. In so doing, it is argued, they are committing the language-as-fixed-effect fallacy, which can lead to serious error. The problem is illustrated for one well-known series of studies in semantic memory. With the appropriate statistics these studies are shown to provide no reliable evidence for most of the main conclusions drawn from them. A review of other experiments in semantic memory shows that many of them are likewise suspect. It is demonstrated how this fallacy can be avoided by doing the right statistics, selecting the appropriate design, and sampling by systematic procedures, or, alternatively, by proceeding according to the so-called method of single cases.},
	number = {4},
	urldate = {2023-12-28},
	journal = {Journal of Verbal Learning and Verbal Behavior},
	author = {Clark, Herbert H.},
	month = aug,
	year = {1973},
	pages = {335--359},
	file = {ScienceDirect Snapshot:/home/babymagikarp/Zotero/storage/K6FND5JK/S0022537173800143.html:text/html},
}

@article{coleman_generalizing_1964,
	title = {Generalizing to a {Language} {Population}},
	volume = {14},
	issn = {0033-2941},
	url = {https://doi.org/10.2466/pr0.1964.14.1.219},
	doi = {10.2466/pr0.1964.14.1.219},
	abstract = {Many studies of verbal behavior have little scientific point if their conclusions have to be restricted to the specific language materials that were used in the experiment. It has not been customary, however, to perform significance tests that permit generalization beyond these specific materials, and thus there is little statistical evidence that such studies could be successfully replicated if a different sample of language materials were used. Three tests are described that will allow generalization to a population of language materials.},
	language = {en},
	number = {1},
	urldate = {2023-12-28},
	journal = {Psychological Reports},
	author = {Coleman, E. B.},
	month = feb,
	year = {1964},
	note = {Publisher: SAGE Publications Inc},
	pages = {219--226},
	file = {SAGE PDF Full Text:/home/babymagikarp/Zotero/storage/EDK937KL/Coleman - 1964 - Generalizing to a Language Population.pdf:application/pdf},
}
